{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7a2c534-c854-4afa-8d8b-f2d0996485be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year 2022\n",
      "  2022: fetched 1437 rows\n",
      "year 2023\n",
      "  2023: fetched 1057 rows\n",
      "year 2024\n",
      "  2024: fetched 629 rows\n",
      "year 2025\n",
      "  2025: fetched 185 rows\n",
      "Upserting 1437 rows in batches of 1000...\n",
      "  Batch 1: 1000 rows\n",
      "  Batch 2: 437 rows\n",
      "✅ Loaded 1437 rows in 6.2s\n",
      "🏃 View run Load 30yr Auction Results at: http://127.0.0.1:8768/#/experiments/1447/runs/73f1bfe35ea240559855eeb87f4d4d1b\n",
      "🧪 View experiment at: http://127.0.0.1:8768/#/experiments/1447\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import time\n",
    "from datetime import date\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from pathlib import Path\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "from domino.data_sources import DataSourceClient\n",
    "\n",
    "API_BASE   = \"https://api.fiscaldata.treasury.gov/services/api/fiscal_service/v1/accounting/od/auctions_query\"\n",
    "PAGE_SIZE  = 10000   # plenty for a single year\n",
    "BATCH_SIZE = 1000     # rows per upsert batch\n",
    "\n",
    "mlflow.set_experiment(\"Populate DB (treasury_auction_results)\")\n",
    "ds = DataSourceClient().get_datasource(\"market_data\")\n",
    "\n",
    "def fetch_all_auctions_last_y(years_to_backfill) -> list[dict]:\n",
    "    rows = []\n",
    "    start_year = (date.today() - relativedelta(years=years_to_backfill)).year\n",
    "    end_year   = date.today().year\n",
    "\n",
    "    for yr in range(start_year, end_year + 1):\n",
    "        print('year', yr)\n",
    "        start = date(yr, 1, 1).isoformat()\n",
    "        end   = date(yr, 12, 31).isoformat()\n",
    "        params = [\n",
    "            (\"filter\", f\"record_date:gte:{start}\"),\n",
    "            (\"filter\", f\"record_date:lte:{end}\"),\n",
    "            (\"page[size]\", str(PAGE_SIZE)),\n",
    "            (\"sort\", \"record_date\"),\n",
    "        ]\n",
    "        resp = requests.get(API_BASE, params=params)\n",
    "        resp.raise_for_status()\n",
    "        data = resp.json().get(\"data\", [])\n",
    "        print(f\"  {yr}: fetched {len(data)} rows\")\n",
    "        rows.extend(data)\n",
    "    return rows\n",
    "\n",
    "def quote_value(val):\n",
    "    if val is None or val == \"null\":\n",
    "        return \"NULL\"\n",
    "    try:\n",
    "        float(val)\n",
    "        return str(val)\n",
    "    except:\n",
    "        return \"'\" + str(val).replace(\"'\", \"''\") + \"'\"\n",
    "\n",
    "def chunks(lst, n):\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i : i + n]\n",
    "\n",
    "def dedupe(records: list[dict]) -> list[dict]:\n",
    "    seen = set()\n",
    "    deduped = []\n",
    "    for r in records:\n",
    "        key = (r.get(\"record_date\"), r.get(\"cusip\"))\n",
    "        if key in seen:\n",
    "            continue\n",
    "        seen.add(key)\n",
    "        deduped.append(r)\n",
    "    return deduped\n",
    "\n",
    "def upsert_batch(records: list[dict], batch_size: int = BATCH_SIZE):\n",
    "    if not records:\n",
    "        return\n",
    "    cols = list(records[0].keys())\n",
    "    col_list = \", \".join(cols)\n",
    "    total = len(records)\n",
    "    print(f\"Upserting {total} rows in batches of {batch_size}...\")\n",
    "    for idx, chunk in enumerate(chunks(records, batch_size), start=1):\n",
    "        print(f\"  Batch {idx}: {len(chunk)} rows\")\n",
    "        values_sql = []\n",
    "        for r in chunk:\n",
    "            vals = [quote_value(r.get(c)) for c in cols]\n",
    "            values_sql.append(\"(\" + \", \".join(vals) + \")\")\n",
    "        values_str = \",\\n\".join(values_sql)\n",
    "        set_list = \", \".join([f\"{c} = EXCLUDED.{c}\" for c in cols])\n",
    "        sql = f\"\"\"\n",
    "        INSERT INTO treasury_auction_results ({col_list})\n",
    "        VALUES\n",
    "        {values_str}\n",
    "        ON CONFLICT (record_date, cusip)\n",
    "        DO UPDATE SET\n",
    "          {set_list};\n",
    "        \"\"\"\n",
    "        ds.query(sql)\n",
    "\n",
    "def main(years_to_backfill):\n",
    "    with mlflow.start_run(run_name=\"Load 30yr Auction Results\"):\n",
    "        t0 = time.time()\n",
    "\n",
    "        data = fetch_all_auctions_last_y(years_to_backfill)\n",
    "        mlflow.log_metric(\"rows_fetched\", len(data))\n",
    "        data = dedupe(data)\n",
    "        upsert_batch(data)\n",
    "\n",
    "        duration = time.time() - t0\n",
    "        mlflow.log_metric(\"duration_seconds\", duration)\n",
    "        print(f\"✅ Loaded {len(data)} rows in {duration:.1f}s\")\n",
    "\n",
    "        def find_mount_root(start: Path, target: str = \"mnt\") -> Path:\n",
    "            \"\"\"Climb up until we find the given folder name.\"\"\"\n",
    "            current = start.resolve()\n",
    "            while current.name != target:\n",
    "                if current.parent == current:\n",
    "                    raise FileNotFoundError(f\"Could not find folder named '{target}' in parent paths.\")\n",
    "                current = current.parent\n",
    "            return current\n",
    "        \n",
    "        df = pd.DataFrame(data)\n",
    "        mnt_root = find_mount_root(Path.cwd())\n",
    "        out = mnt_root / \"artifacts\" / \"results\" / \"treasury_auction_results.csv\"\n",
    "        out.parent.mkdir(parents=True, exist_ok=True)\n",
    "        df.to_csv(out, index=False)\n",
    "        mlflow.log_artifact(str(out), artifact_path=\"treasury_auction_results\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(years_to_backfill = 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309d5914-6d2e-403b-8812-567f4d08b4d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
