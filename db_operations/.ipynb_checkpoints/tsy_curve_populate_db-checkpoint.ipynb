{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4753bf2-0c13-492f-afae-f28616da8db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows [('US Treasury Par', '2025-05-16', '1 Mo', 4.37, 0.08333333333333333), ('US Treasury Par', '2025-05-16', '1.5 Month', 4.36, 0.125), ('US Treasury Par', '2025-05-16', '2 Mo', 4.34, 0.16666666666666666), ('US Treasury Par', '2025-05-16', '3 Mo', 4.37, 0.25), ('US Treasury Par', '2025-05-16', '4 Mo', 4.42, 0.3333333333333333), ('US Treasury Par', '2025-05-16', '6 Mo', 4.3, 0.5), ('US Treasury Par', '2025-05-16', '1 Yr', 4.13, 1.0), ('US Treasury Par', '2025-05-16', '2 Yr', 3.98, 2.0), ('US Treasury Par', '2025-05-16', '3 Yr', 3.95, 3.0), ('US Treasury Par', '2025-05-16', '5 Yr', 4.06, 5.0), ('US Treasury Par', '2025-05-16', '7 Yr', 4.24, 7.0), ('US Treasury Par', '2025-05-16', '10 Yr', 4.43, 10.0), ('US Treasury Par', '2025-05-16', '20 Yr', 4.92, 20.0), ('US Treasury Par', '2025-05-16', '30 Yr', 4.89, 30.0)]\n",
      "2025: prepared 14 rows\n",
      "✅ Done bulk-loading rate_curves from 2025-05-16 through 2025-05-19\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from domino.data_sources import DataSourceClient\n",
    "from datetime import date\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from functools import lru_cache\n",
    "import requests\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "import mlflow\n",
    "import os\n",
    "\n",
    "starting_domino_user = os.environ[\"DOMINO_STARTING_USERNAME\"]\n",
    "experiment_name = f\"Domino_Experiment_{starting_domino_user}\"\n",
    "mlflow.set_experiment(experiment_name=experiment_name)\n",
    "\n",
    "# ─── Helpers ────────────────────────────────────────────────────────────────\n",
    "\n",
    "@lru_cache(maxsize=100)\n",
    "def fetch_treasury_csv(year: int) -> str:\n",
    "    url = (\n",
    "        f\"https://home.treasury.gov/resource-center/data-chart-center/interest-rates/\"\n",
    "        f\"daily-treasury-rates.csv/{year}/all\"\n",
    "        f\"?field_tdr_date_value={year}\"\n",
    "        f\"&type=daily_treasury_yield_curve&page&_format=csv\"\n",
    "    )\n",
    "    resp = requests.get(url)\n",
    "    resp.raise_for_status()\n",
    "    return resp.text\n",
    "\n",
    "def parse_tenor(tenor_str: str) -> float:\n",
    "    num_str, unit = tenor_str.strip().split(maxsplit=1)\n",
    "    n = float(num_str); u = unit.lower()\n",
    "    if u.startswith('mo'):   return (n * 30) / 360\n",
    "    if u.startswith('yr'):   return n\n",
    "    if u.startswith('day'):  return n / 360\n",
    "    raise ValueError(f\"Unknown tenor unit: '{unit}'\")\n",
    "\n",
    "def prepare_year_rows(year, start_date, end_date):\n",
    "    \"\"\"\n",
    "    Fetch & parse a single year's CSV, return a flat list of rows:\n",
    "    (curve_type, date, tenor, rate, tenor_num)\n",
    "    \"\"\"\n",
    "    text = fetch_treasury_csv(year)\n",
    "    df   = pd.read_csv(StringIO(text), parse_dates=['Date'], index_col='Date')\n",
    "    # filter to window\n",
    "    df = df[(df.index.date >= start_date) & (df.index.date <= end_date)]\n",
    "    rows = []\n",
    "    for ts, row in df.iterrows():\n",
    "        d = ts.date()\n",
    "        for tenor, rate in row.items():\n",
    "            if pd.isna(rate):\n",
    "                continue\n",
    "            rows.append((\n",
    "                'US Treasury Par',\n",
    "                d.isoformat(),\n",
    "                tenor,\n",
    "                float(rate),\n",
    "                parse_tenor(tenor)\n",
    "            ))\n",
    "    return year, rows\n",
    "\n",
    "# ─── Main loader ────────────────────────────────────────────────────────────\n",
    "\n",
    "ds = DataSourceClient().get_datasource(\"market_data\")\n",
    "\n",
    "def populate(\n",
    "    days: int,\n",
    "    batch_size: int    = 5000,\n",
    "    fetch_workers: int = 4,\n",
    "    write_workers: int = 2\n",
    "):\n",
    "    \"\"\"\n",
    "    Populate rate_curves for the last `days` days (up to today),\n",
    "    but not before 2010-03-15.\n",
    "    \"\"\"\n",
    "    # calculate date range\n",
    "    end_date = date.today()\n",
    "    start_date = end_date - relativedelta(days=days)\n",
    "    min_date = date(2010, 3, 15)\n",
    "    if start_date < min_date:\n",
    "        start_date = min_date\n",
    "\n",
    "    years = list(range(start_date.year, end_date.year + 1))\n",
    "\n",
    "    # 1) parallel fetch + parse per-year\n",
    "    rows_by_year = {}\n",
    "    with ThreadPoolExecutor(max_workers=fetch_workers) as fetch_pool:\n",
    "        futures = {\n",
    "            fetch_pool.submit(prepare_year_rows, y, start_date, end_date): y\n",
    "            for y in years\n",
    "        }\n",
    "        for fut in as_completed(futures):\n",
    "            y = futures[fut]\n",
    "            try:\n",
    "                year, rows = fut.result()\n",
    "                if rows:\n",
    "                    rows_by_year[year] = rows\n",
    "                    print(f\"{year}: prepared {len(rows)} rows\")\n",
    "                else:\n",
    "                    print(f\"{year}: no data → skipped\")\n",
    "            except Exception as e:\n",
    "                print(f\"{y}: error fetching/parsing → {e}\")\n",
    "\n",
    "    # 2) for each year, batch & fire INSERTs in parallel\n",
    "    def write_batch(batch):\n",
    "        vals = \", \".join(\n",
    "            f\"('{r[0]}','{r[1]}','{r[2]}',{r[3]},{r[4]})\"\n",
    "            for r in batch\n",
    "        )\n",
    "        sql = f\"\"\"\n",
    "            INSERT INTO rate_curves\n",
    "              (curve_type, curve_date, tenor_str, rate, tenor_num)\n",
    "            VALUES\n",
    "              {vals}\n",
    "            ON CONFLICT (curve_type, curve_date, tenor_str) DO UPDATE\n",
    "              SET rate      = EXCLUDED.rate,\n",
    "                  tenor_num = EXCLUDED.tenor_num;\n",
    "            \"\"\"\n",
    "        ds.query(sql)\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=write_workers) as write_pool:\n",
    "        write_futures = []\n",
    "        for year, rows in rows_by_year.items():\n",
    "            for i in range(0, len(rows), batch_size):\n",
    "                batch = rows[i : i + batch_size]\n",
    "                write_futures.append(write_pool.submit(write_batch, batch))\n",
    "\n",
    "        for fut in as_completed(write_futures):\n",
    "            try:\n",
    "                fut.result()\n",
    "            except Exception as e:\n",
    "                print(f\"Write error: {e}\")\n",
    "\n",
    "    print(\"✅ Done bulk-loading rate_curves \"\n",
    "          f\"from {start_date} through {end_date}\")\n",
    "\n",
    "\n",
    "# arg1 is the number of days to backdate.\n",
    "# 1 => yesterday's curve, 100 => last 100 days.\n",
    "default_backdated_days = 3\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    d = default_backdated_days\n",
    "else:\n",
    "    try:\n",
    "        days_to_backdate = sys.argv[1]\n",
    "        d = int(days_to_backdate)\n",
    "    except Exception as e:\n",
    "        d = default_backdated_days\n",
    "\n",
    "populate(days=d)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ba97e5-96ae-4277-af4b-8ac622368a1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
