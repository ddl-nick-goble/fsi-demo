{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7a2c534-c854-4afa-8d8b-f2d0996485be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/30 15:29:04 INFO mlflow.tracking.fluent: Experiment with name 'PCA Training [sandbox]' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting data source for sandbox\n",
      "running for 2025-05-30\n",
      "mse 0.0011685214452618155\n",
      "r2 0.996804050339113\n",
      "‚úÖ PCA run complete (run_id: 0c530424-1f47-4bb2-b1b2-b890a5198ea2). Logged metrics and artifact.\n",
      "üèÉ View run PCA_2025-05-30 at: http://127.0.0.1:8768/#/experiments/1462/runs/2dfdf98854674cc580f6d408243c9eed\n",
      "üß™ View experiment at: http://127.0.0.1:8768/#/experiments/1462\n",
      "running for 2025-05-29\n",
      "mse 0.0011685214452618155\n",
      "r2 0.996804050339113\n",
      "‚úÖ PCA run complete (run_id: 55391c5e-d67f-4ab8-bab8-38358ee40571). Logged metrics and artifact.\n",
      "üèÉ View run PCA_2025-05-29 at: http://127.0.0.1:8768/#/experiments/1462/runs/c01b705dee00445daab8a6f67b0e34e0\n",
      "üß™ View experiment at: http://127.0.0.1:8768/#/experiments/1462\n",
      "running for 2025-05-28\n",
      "mse 0.0011575379293504858\n",
      "r2 0.9968362578333282\n",
      "‚úÖ PCA run complete (run_id: 56e70a37-5a5b-4f5a-b7a2-44222e7a731b). Logged metrics and artifact.\n",
      "üèÉ View run PCA_2025-05-28 at: http://127.0.0.1:8768/#/experiments/1462/runs/c7937db3bc0d496eaffe560bc4364329\n",
      "üß™ View experiment at: http://127.0.0.1:8768/#/experiments/1462\n",
      "running for 2025-05-27\n",
      "mse 0.0011476005870515616\n",
      "r2 0.9969094443592609\n",
      "‚úÖ PCA run complete (run_id: 6d3ad723-4155-4165-85ab-b2accaf89eb1). Logged metrics and artifact.\n",
      "üèÉ View run PCA_2025-05-27 at: http://127.0.0.1:8768/#/experiments/1462/runs/cbb54a331e204fa782827bd55d351be5\n",
      "üß™ View experiment at: http://127.0.0.1:8768/#/experiments/1462\n",
      "running for 2025-05-26\n",
      "mse 0.001138469228825607\n",
      "r2 0.9969786913883806\n",
      "‚úÖ PCA run complete (run_id: 231ed4b9-a9ad-433e-9872-41052a72d255). Logged metrics and artifact.\n",
      "üèÉ View run PCA_2025-05-26 at: http://127.0.0.1:8768/#/experiments/1462/runs/deafeff75b93418cabfc583c35591bc4\n",
      "üß™ View experiment at: http://127.0.0.1:8768/#/experiments/1462\n",
      "üèÉ View run Rolling PCA at: http://127.0.0.1:8768/#/experiments/1462/runs/3cf28e33e26646f9a248fd5d4de071f6\n",
      "üß™ View experiment at: http://127.0.0.1:8768/#/experiments/1462\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "\n",
    "import data.data_source as data_source\n",
    "\n",
    "import time\n",
    "import uuid\n",
    "import json\n",
    "from datetime import date, timedelta\n",
    "from functools import lru_cache\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import os\n",
    "from config import env\n",
    "from models.pca_model import legacy_pca\n",
    "\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ CONFIGURATION ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "TENORS = [0.25, 0.5, 1, 2, 3, 5, 7, 10, 20, 30]\n",
    "ROLLING_YEARS = 3\n",
    "N_COMPONENTS = 3\n",
    "CURVE_TYPE = \"US Treasury Par\"\n",
    "pca_model = legacy_pca\n",
    "\n",
    "# MLflow experiment\n",
    "experiment_name = f\"PCA Training [{env}]\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ DATASOURCE ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "ds = data_source.get_data_source()\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ HELPERS ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "@lru_cache(maxsize=100)\n",
    "def load_curve_data(start_date: date, end_date: date) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load treasury curves from the database between start_date and end_date.\n",
    "    \"\"\"\n",
    "    sql = f\"\"\"\n",
    "        SELECT curve_date, tenor_num AS tenor, rate\n",
    "          FROM rate_curves\n",
    "         WHERE curve_date BETWEEN '{start_date}' AND '{end_date}'\n",
    "           AND curve_type = '{CURVE_TYPE}'\n",
    "        ORDER BY curve_date\n",
    "    \"\"\"\n",
    "    df = ds.query(sql).to_pandas()\n",
    "    df['curve_date'] = pd.to_datetime(df['curve_date'])\n",
    "    return df\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ PCA + DB INSERT + MLflow LOGGING ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def run_pca_and_log(as_of_date: date):\n",
    "    # Calculate rolling window dates\n",
    "    start_date = as_of_date - relativedelta(years=ROLLING_YEARS)\n",
    "    end_date = as_of_date\n",
    "\n",
    "    # Start timing\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Load data\n",
    "    df = load_curve_data(start_date, end_date)\n",
    "    pivot = (\n",
    "        df.pivot(index=\"curve_date\", columns=\"tenor\", values=\"rate\")\n",
    "          .reindex(columns=[t for t in TENORS if t in df['tenor'].unique()])\n",
    "    )\n",
    "    pivot = pivot.ffill().bfill()\n",
    "    X = pivot.to_numpy()\n",
    "    num_obs, num_tenors = X.shape\n",
    "    means     = X.mean(axis=0)\n",
    "    total_var = ((X - means)**2).mean()\n",
    "\n",
    "    # Fit PCA\n",
    "    components, explained_ratio, mean_curve, all_scores = pca_model(X, N_COMPONENTS)\n",
    "    today_scores = all_scores[-1]   # last row is ‚Äútoday‚Äù\n",
    "\n",
    "    # Compute reconstruction errors\n",
    "    X_recon  = all_scores @ components + mean_curve\n",
    "    mse      = ((X - X_recon)**2).mean()\n",
    "    r2      = 1 - mse      / total_var\n",
    "    print('mse', mse)\n",
    "    print('r2', r2)\n",
    "\n",
    "    total_explained = float(explained_ratio.sum())\n",
    "    run_duration = time.time() - start_time\n",
    "\n",
    "    stats = {\n",
    "        \"run_duration\": run_duration,\n",
    "        \"reconstruction_mse\": float(mse),\n",
    "        \"pc1_variance\":       float(explained_ratio[0]),\n",
    "        \"pc2_variance\":       float(explained_ratio[1]),\n",
    "        \"pc3_variance\":       float(explained_ratio[2]),\n",
    "        \"total_explained\":    total_explained\n",
    "    }\n",
    "    with open(\"../../artifacts/results/dominostats.json\", \"w\") as f:\n",
    "        json.dump(stats, f)\n",
    "\n",
    "    # Generate a run_id\n",
    "    run_id = str(uuid.uuid4())\n",
    "\n",
    "    # Insert into DB\n",
    "    insert_sql = f\"\"\"\n",
    "    INSERT INTO pca_results (\n",
    "      run_id, curve_type, curve_date, n_components,\n",
    "      total_explained_variance_ratio, explained_variance_ratios,\n",
    "      mean_curve, components, scores\n",
    "    ) VALUES (\n",
    "      '{run_id}', '{CURVE_TYPE}', '{as_of_date}',\n",
    "      {N_COMPONENTS}, {total_explained},\n",
    "      ARRAY{explained_ratio.tolist()},\n",
    "      ARRAY{mean_curve.tolist()},\n",
    "      '{json.dumps(components.tolist()).replace(\"'\", \"''\")}',\n",
    "      ARRAY{today_scores.tolist()}\n",
    "    )\n",
    "    ON CONFLICT (curve_type, curve_date)\n",
    "    DO UPDATE SET\n",
    "      run_id                        = EXCLUDED.run_id,\n",
    "      run_timestamp                 = CLOCK_TIMESTAMP(),\n",
    "      n_components                  = EXCLUDED.n_components,\n",
    "      total_explained_variance_ratio= EXCLUDED.total_explained_variance_ratio,\n",
    "      explained_variance_ratios     = EXCLUDED.explained_variance_ratios,\n",
    "      mean_curve                    = EXCLUDED.mean_curve,\n",
    "      components                    = EXCLUDED.components,\n",
    "      scores                        = EXCLUDED.scores;\n",
    "    \"\"\"\n",
    "    ds.query(insert_sql)\n",
    "    \n",
    "    # MLflow logging\n",
    "    mlflow.log_param(\"as_of_date\", as_of_date)\n",
    "    mlflow.log_param(\"as_of_date_ordinal\", as_of_date.toordinal() - 733773)\n",
    "    mlflow.log_param(\"rolling_years\", ROLLING_YEARS)\n",
    "    mlflow.log_param(\"n_components\", N_COMPONENTS)\n",
    "    mlflow.log_param(\"curve_type\", CURVE_TYPE)\n",
    "    mlflow.log_param(\"num_tenors\", num_tenors)\n",
    "    mlflow.log_param(\"num_observations\", num_obs)\n",
    "    mlflow.log_param(\"pca_model\", pca_model.__name__)\n",
    "    mlflow.log_param(\"starting_domino_user\", os.environ[\"DOMINO_STARTING_USERNAME\"])\n",
    "\n",
    "\n",
    "    mlflow.log_metric(\"reconstruction_mse\", float(mse))\n",
    "    mlflow.log_metric(\"total_explained_variance\", total_explained)\n",
    "    for i, ratio in enumerate(explained_ratio, start=1):\n",
    "        mlflow.log_metric(f\"explained_variance_ratio_{i}\", float(ratio))\n",
    "    mlflow.log_metric(\"run_duration_seconds\", run_duration)\n",
    "\n",
    "    # Create DataFrame for artifact\n",
    "    metrics_df = pd.DataFrame({\n",
    "        'component': list(range(1, N_COMPONENTS+1)),\n",
    "        'explained_variance_ratio': explained_ratio\n",
    "    })\n",
    "    metrics_df['cumulative_variance'] = metrics_df['explained_variance_ratio'].cumsum()\n",
    "\n",
    "    # Save artifact\n",
    "    csv_path = \"../../artifacts/results/rate_curves_loaded.csv\"\n",
    "    metrics_df.to_csv(csv_path, index=False)\n",
    "    mlflow.log_artifact(csv_path, artifact_path=\"pca_metrics\")\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(\n",
    "        np.arange(1, N_COMPONENTS + 1),\n",
    "        explained_ratio,\n",
    "        marker='o',\n",
    "        linestyle='-',\n",
    "    )\n",
    "    ax.set_xlabel(\"Principal Component\")\n",
    "    ax.set_ylabel(\"Explained Variance Ratio\")\n",
    "    ax.set_title(f\"Scree Plot (as_of={as_of_date})\")\n",
    "    \n",
    "    # 2) save locally\n",
    "    plot_path = f\"../../artifacts/results/scree_{as_of_date}.png\"\n",
    "    fig.savefig(plot_path, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    \n",
    "    # 3) log to MLflow\n",
    "    mlflow.log_artifact(plot_path, artifact_path=\"scree_plots\")\n",
    "\n",
    "    print(f\"‚úÖ PCA run complete (run_id: {run_id}). Logged metrics and artifact.\")\n",
    "\n",
    "def populate(days, starting_date):\n",
    "    d = starting_date\n",
    "    start_time = time.time()\n",
    "    end_date = date.today()\n",
    "    start_date = end_date - relativedelta(days=days)\n",
    "    min_date = date(2010, 3, 15)\n",
    "    unique_dates = set()\n",
    "    if start_date < min_date:\n",
    "        start_date = min_date\n",
    "\n",
    "    with mlflow.start_run(run_name=\"Rolling PCA\", nested=False):\n",
    "        mlflow.log_param(\"days_requested\", days)\n",
    "        mlflow.log_param(\"starting_domino_user\", os.environ[\"DOMINO_STARTING_USERNAME\"])\n",
    "        mlflow.log_param(\"curve_type\", CURVE_TYPE)\n",
    "        mlflow.log_param(\"rolling_years\", ROLLING_YEARS)\n",
    "        mlflow.log_param(\"n_components\", N_COMPONENTS)\n",
    "        mlflow.log_param(\"curve_type\", CURVE_TYPE)\n",
    "        mlflow.log_param(\"pca_model\", pca_model.__name__)\n",
    "\n",
    "\n",
    "        for i in range(days):\n",
    "            as_of_date = d - relativedelta(days=i)\n",
    "            print(f'running for {as_of_date}')\n",
    "            with mlflow.start_run(nested=True, run_name=f\"PCA_{as_of_date}\"):\n",
    "                run_pca_and_log(as_of_date)\n",
    "                mlflow.end_run()\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ MAIN ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    \n",
    "default_backdated_days = 5\n",
    "default_as_of = date.today()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if len(sys.argv) > 1:\n",
    "        try:\n",
    "            as_of = date.fromisoformat(sys.argv[1])\n",
    "        except ValueError:\n",
    "            as_of = default_as_of\n",
    "    else:\n",
    "        as_of = default_as_of\n",
    "\n",
    "    populate(default_backdated_days, as_of)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138a932d-9e3c-41c9-8458-8936918a14c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
