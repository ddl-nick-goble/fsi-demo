{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4753bf2-0c13-492f-afae-f28616da8db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting data source for sandbox\n",
      "✅ Inserted 70 rows into rate_cones for ASOF=2025-06-02.\n",
      "✅ Inserted 70 rows into rate_cones for ASOF=2025-06-04.\n",
      "✅ Inserted 70 rows into rate_cones for ASOF=2025-06-03.\n",
      "✅ Inserted 70 rows into rate_cones for ASOF=2025-06-01.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'EmpiricalCovarianceModel' already exists. Creating a new version of this model...\n",
      "2025/06/06 23:14:07 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: EmpiricalCovarianceModel, version 19\n",
      "Created version '19' of model 'EmpiricalCovarianceModel'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run IR_2025-06-02 at: http://127.0.0.1:8768/#/experiments/1510/runs/56b81f4a0eb6482c89701527df12cc4f\n",
      "🧪 View experiment at: http://127.0.0.1:8768/#/experiments/1510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'EmpiricalCovarianceModel' already exists. Creating a new version of this model...\n",
      "Registered model 'EmpiricalCovarianceModel' already exists. Creating a new version of this model...\n",
      "Registered model 'EmpiricalCovarianceModel' already exists. Creating a new version of this model...\n",
      "2025/06/06 23:14:08 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: EmpiricalCovarianceModel, version 20\n",
      "Created version '20' of model 'EmpiricalCovarianceModel'.\n",
      "2025/06/06 23:14:08 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: EmpiricalCovarianceModel, version 21\n",
      "Created version '21' of model 'EmpiricalCovarianceModel'.\n",
      "2025/06/06 23:14:08 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: EmpiricalCovarianceModel, version 22\n",
      "Created version '22' of model 'EmpiricalCovarianceModel'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run IR_2025-06-01 at: http://127.0.0.1:8768/#/experiments/1510/runs/d68b1c5ce53a439d95824bdce165bb30\n",
      "🧪 View experiment at: http://127.0.0.1:8768/#/experiments/1510\n",
      "🏃 View run IR_2025-06-04 at: http://127.0.0.1:8768/#/experiments/1510/runs/40b2556b67ab4042888a89e95f8326f5\n",
      "🧪 View experiment at: http://127.0.0.1:8768/#/experiments/1510\n",
      "🏃 View run IR_2025-06-03 at: http://127.0.0.1:8768/#/experiments/1510/runs/a81ca10ff663406bbe08e76b14089d02\n",
      "🧪 View experiment at: http://127.0.0.1:8768/#/experiments/1510\n",
      "✅ Inserted 70 rows into rate_cones for ASOF=2025-06-05.\n",
      "✅ Inserted 70 rows into rate_cones for ASOF=2025-06-06.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'EmpiricalCovarianceModel' already exists. Creating a new version of this model...\n",
      "2025/06/06 23:14:16 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: EmpiricalCovarianceModel, version 23\n",
      "Created version '23' of model 'EmpiricalCovarianceModel'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run IR_2025-06-05 at: http://127.0.0.1:8768/#/experiments/1510/runs/6eb43e288cd7405fb8c03408dcf2944d\n",
      "🧪 View experiment at: http://127.0.0.1:8768/#/experiments/1510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'EmpiricalCovarianceModel' already exists. Creating a new version of this model...\n",
      "2025/06/06 23:14:17 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: EmpiricalCovarianceModel, version 24\n",
      "Created version '24' of model 'EmpiricalCovarianceModel'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run IR_2025-06-06 at: http://127.0.0.1:8768/#/experiments/1510/runs/7c6f7b6bae274086a82e25f6043a3052\n",
      "🧪 View experiment at: http://127.0.0.1:8768/#/experiments/1510\n",
      "✅ All cones processed and logged.\n",
      "🏃 View run populate_ir_cones_2025-06-06 at: http://127.0.0.1:8768/#/experiments/1510/runs/90a8cd6d48bf40e2ad12a2b1e6486809\n",
      "🧪 View experiment at: http://127.0.0.1:8768/#/experiments/1510\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import matplotlib.pyplot as plt\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "from mlflow.models.signature import infer_signature\n",
    "import mlflow.sklearn\n",
    "\n",
    "from data.data_source import get_data_source\n",
    "from data.treasury_curve import get_yield_curve\n",
    "from models.empirical_covariance import EmpiricalCovarianceModel\n",
    "from config import env\n",
    "\n",
    "# ─── CONFIG ─────────────────────────────────────────────────────────────────\n",
    "CURVE_TYPE       = \"US Treasury Par\"\n",
    "TENORS           = [0.25, 0.5, 1, 2, 3, 5, 7, 10, 20, 30]\n",
    "N_SIMS           = 1000\n",
    "MLFLOW_EXPERIMENT = \"IR Cone Monte Carlo Optimized5\"\n",
    "ds               = get_data_source()\n",
    "\n",
    "def batch_insert_rate_cones(records, batch_size=200):\n",
    "    total_inserted = 0\n",
    "    for i in range(0, len(records), batch_size):\n",
    "        batch = records[i:i + batch_size]\n",
    "        values_clause = \",\\n\".join([\n",
    "            f\"('{r['curve_type']}', '{r['cone_type']}', '{r['cone_date']}', '{r['tenor_str']}', {r['rate']:.8f}, {r['tenor_num']:.8f})\"\n",
    "            for r in batch\n",
    "        ])\n",
    "        insert_sql = f\"\"\"\n",
    "        INSERT INTO rate_cones (curve_type, cone_type, cone_date, tenor_str, rate, tenor_num)\n",
    "        VALUES {values_clause}\n",
    "        ON CONFLICT DO NOTHING;\n",
    "        \"\"\"\n",
    "        ds.query(insert_sql)\n",
    "        total_inserted += len(batch)\n",
    "    return total_inserted\n",
    "\n",
    "# ─── UTILS ───────────────────────────────────────────────────────────────────\n",
    "def plot_ir_cones_matplotlib(base_curve: pd.Series, ir_cone_df: pd.DataFrame, title: str = \"\"):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sample_ids = np.random.choice(\n",
    "        ir_cone_df[\"sim_id\"].unique(),\n",
    "        size=min(100, len(ir_cone_df[\"sim_id\"].unique())),\n",
    "        replace=False\n",
    "    )\n",
    "    sample_df = ir_cone_df[ir_cone_df[\"sim_id\"].isin(sample_ids)]\n",
    "    for sim_id in sample_df[\"sim_id\"].unique():\n",
    "        sim_data = sample_df[sample_df[\"sim_id\"] == sim_id]\n",
    "        plt.plot(sim_data[\"tenor_num\"], sim_data[\"rate_simulated\"], color=\"gray\", alpha=0.1)\n",
    "\n",
    "    plt.plot(base_curve.index, base_curve.values,\n",
    "             color=\"crimson\", linewidth=2.5, label=\"Base Curve\")\n",
    "    plt.xlabel(\"Tenor (years)\")\n",
    "    plt.ylabel(\"Yield (%)\")\n",
    "    plt.title(title or f\"Monte Carlo IR Cones ({N_SIMS} sims) on {base_curve.name}\")\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.3)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    filename = f\"../../artifacts/results/tsy_cones_{base_curve.name}.png\"\n",
    "    plt.savefig(filename, dpi=150)\n",
    "    plt.close()\n",
    "    return filename\n",
    "\n",
    "def generate_ir_cone(base_curve: pd.Series,\n",
    "                     cov_model: EmpiricalCovarianceModel,\n",
    "                     n_sims: int = N_SIMS) -> pd.DataFrame:\n",
    "    tenor_order = list(base_curve.index)\n",
    "    cov_mat     = cov_model.covariance_\n",
    "    rand_deltas = np.random.multivariate_normal(\n",
    "        mean=np.zeros(len(tenor_order)),\n",
    "        cov=cov_mat,\n",
    "        size=n_sims\n",
    "    )\n",
    "    base_vals = base_curve.values.reshape((1, -1))\n",
    "    sims      = base_vals + rand_deltas\n",
    "\n",
    "    records = [\n",
    "        {\n",
    "            \"sim_id\": sim,\n",
    "            \"tenor_num\": tenor_order[i],\n",
    "            \"rate_simulated\": sims[sim, i]\n",
    "        }\n",
    "        for sim in range(n_sims)\n",
    "        for i in range(len(tenor_order))\n",
    "    ]\n",
    "    return pd.DataFrame.from_records(records)\n",
    "\n",
    "# ─── MAIN JOB ────────────────────────────────────────────────────────────────\n",
    "def populate_ir_cones(days: int, years_back: int = 0, max_workers: int = 4):\n",
    "    end_date  = datetime.today().date()\n",
    "    start_date = max(\n",
    "        end_date - relativedelta(days=days, years=years_back),\n",
    "        datetime(2010, 1, 1).date()\n",
    "    )\n",
    "    all_dates = pd.date_range(start=start_date, end=end_date, freq='D').date\n",
    "\n",
    "    mlflow.set_experiment(MLFLOW_EXPERIMENT)\n",
    "    client = MlflowClient()\n",
    "\n",
    "    # Parent run\n",
    "    with mlflow.start_run(run_name=f\"populate_ir_cones_{end_date}\") as parent:\n",
    "        parent_id = parent.info.run_id\n",
    "        mlflow.log_params({\n",
    "            \"as_of_date\": start_date,\n",
    "            \"days_requested\": days,\n",
    "            \"curve_type\": CURVE_TYPE,\n",
    "            \"n_sims\": N_SIMS,\n",
    "        })\n",
    "\n",
    "        # accumulate for parent‐level summary\n",
    "        total_vars, trace_covs, total_obs = [], [], []\n",
    "        errors = []\n",
    "\n",
    "        def task(asof_date):\n",
    "            try:\n",
    "                # 1) Fetch & pivot\n",
    "                sql = f\"\"\"\n",
    "                SELECT curve_date, tenor_num, rate FROM rate_curves\n",
    "                WHERE curve_type = '{CURVE_TYPE}'\n",
    "                  AND curve_date <= '{asof_date}'\n",
    "                  AND tenor_num IN ({', '.join(map(str, TENORS))})\n",
    "                ORDER BY curve_date DESC, tenor_num;\n",
    "                \"\"\"\n",
    "                df = ds.query(sql).to_pandas()\n",
    "                if df.empty:\n",
    "                    return (asof_date, \"No curve data\")\n",
    "\n",
    "                pivot = (\n",
    "                    df.pivot(index=\"curve_date\", columns=\"tenor_num\", values=\"rate\")\n",
    "                      .sort_index()\n",
    "                      .interpolate(method=\"linear\", axis=0)\n",
    "                      .dropna()\n",
    "                )\n",
    "\n",
    "                asof_actual = (\n",
    "                    asof_date\n",
    "                    if asof_date in pivot.index\n",
    "                    else pivot.index[pivot.index <= asof_date].max()\n",
    "                )\n",
    "                base_curve = pivot.loc[asof_actual]\n",
    "                deltas     = pivot.diff().dropna()\n",
    "\n",
    "                # 2) Fit & simulate\n",
    "                model    = EmpiricalCovarianceModel().fit(deltas.values)\n",
    "                cone_df  = generate_ir_cone(base_curve, model, n_sims=N_SIMS)\n",
    "                chart_fp = plot_ir_cones_matplotlib(base_curve, cone_df)\n",
    "\n",
    "                percentiles = [1, 5, 10, 50, 90, 95, 99]\n",
    "                \n",
    "                percentile_curves = (\n",
    "                    cone_df\n",
    "                    .groupby(\"tenor_num\")[\"rate_simulated\"]\n",
    "                    .quantile([p / 100 for p in percentiles])\n",
    "                    .unstack(level=1)\n",
    "                    .reset_index()\n",
    "                    .melt(id_vars=\"tenor_num\", var_name=\"percentile\", value_name=\"rate\")\n",
    "                )\n",
    "                \n",
    "                # Convert percentile column back to float\n",
    "                percentile_curves[\"percentile\"] = percentile_curves[\"percentile\"].astype(float)\n",
    "                \n",
    "                # Add required fields\n",
    "                percentile_curves[\"curve_type\"] = CURVE_TYPE\n",
    "                percentile_curves[\"cone_date\"] = asof_date\n",
    "                percentile_curves[\"tenor_str\"] = percentile_curves[\"tenor_num\"].apply(lambda x: f\"{int(x)}Y\" if x.is_integer() else f\"{x}Y\")\n",
    "                percentile_curves[\"cone_type\"] = percentile_curves[\"percentile\"].apply(lambda p: f\"{int(p*100)}%\")\n",
    "                \n",
    "                records = percentile_curves[[\n",
    "                    \"curve_type\", \"cone_type\", \"cone_date\", \"tenor_str\", \"rate\", \"tenor_num\"\n",
    "                ]].to_dict(orient=\"records\")\n",
    "                \n",
    "                n_inserted = batch_insert_rate_cones(records, batch_size=200)\n",
    "                print(f\"✅ Inserted {n_inserted} rows into rate_cones for ASOF={asof_date}.\")\n",
    "\n",
    "                \n",
    "                # summary stats\n",
    "                n_obs     = len(deltas)\n",
    "                total_var = float(np.var(deltas.values))\n",
    "                trace_cov = float(np.trace(model.covariance_))\n",
    "\n",
    "                # collect for parent summary\n",
    "                total_obs.append(n_obs)\n",
    "                total_vars.append(total_var)\n",
    "                trace_covs.append(trace_cov)\n",
    "\n",
    "                # 3) Log & register in a nested run\n",
    "                #    Give MLflow an input_example so it auto-inferrs a signature\n",
    "                input_example = deltas.values[:1]  # one row of deltas\n",
    "                with mlflow.start_run(\n",
    "                    run_name=f\"IR_{asof_date}\",\n",
    "                    nested=True,\n",
    "                    tags={\"mlflow.parentRunId\": parent_id}\n",
    "                ):\n",
    "                    mlflow.log_param(\"as_of_date\", str(asof_actual))\n",
    "                    mlflow.log_param(\"days_requested\", days)\n",
    "                    mlflow.log_param(\"curve_type\", CURVE_TYPE)\n",
    "                    mlflow.log_param(\"n_sims\", N_SIMS)\n",
    "                    mlflow.log_metric(\"n_obs\", n_obs)\n",
    "                    mlflow.log_metric(\"total_var\", total_var)\n",
    "                    mlflow.log_metric(\"trace_cov\", trace_cov)\n",
    "                    mlflow.log_metric(\"dates_processed\", 1)\n",
    "\n",
    "                    # Log+register\n",
    "                    mlflow.sklearn.log_model(\n",
    "                        sk_model=model,\n",
    "                        artifact_path=\"model\",\n",
    "                        registered_model_name=\"EmpiricalCovarianceModel\",\n",
    "                        input_example=input_example\n",
    "                    )\n",
    "\n",
    "                    # Chart\n",
    "                    mlflow.log_artifact(chart_fp, artifact_path=\"charts\")\n",
    "\n",
    "                return None\n",
    "\n",
    "            except Exception as e:\n",
    "                return (asof_date, str(e))\n",
    "\n",
    "        # dispatch\n",
    "        with ThreadPoolExecutor(max_workers=max_workers) as exe:\n",
    "            futures = [exe.submit(task, d) for d in all_dates]\n",
    "            for fut in as_completed(futures):\n",
    "                if (err := fut.result()):\n",
    "                    errors.append(err)\n",
    "\n",
    "        # Parent summary metrics\n",
    "        mlflow.log_metric(\"dates_processed\", len(all_dates) - len(errors))\n",
    "        mlflow.log_metric(\"n_errors\", len(errors))\n",
    "        mlflow.log_metric(\"n_obs\", sum(total_obs))\n",
    "        mlflow.log_metric(\"total_var\", float(np.mean(total_vars)))\n",
    "        mlflow.log_metric(\"trace_cov\", float(np.mean(trace_covs)))\n",
    "\n",
    "        # report\n",
    "        if errors:\n",
    "            print(f\"⚠️  {len(errors)} errors:\")\n",
    "            for d, msg in errors:\n",
    "                print(f\"  • {d}: {msg}\")\n",
    "        else:\n",
    "            print(\"✅ All cones processed and logged.\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    days=5\n",
    "    populate_ir_cones(days=days, years_back=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ba97e5-96ae-4277-af4b-8ac622368a1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
